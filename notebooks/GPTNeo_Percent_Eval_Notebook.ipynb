{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1552d8e",
   "metadata": {},
   "source": [
    "# ðŸ“Š GPT-Neo Evaluation on Filtered Percentage-Based Questions\n",
    "This notebook uses `dev_percent_cleaned.json`, evaluates GPT-Neo predictions using strict and numeric-based metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b1d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221dba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned percentage-based questions\n",
    "with open(\"dev_percent_cleaned.json\") as f:\n",
    "    dev_data = json.load(f)\n",
    "\n",
    "qa_pairs = [(e[\"question\"], e[\"answer\"]) for e in dev_data if \"question\" in e and \"answer\" in e]\n",
    "print(f\"Loaded {len(qa_pairs)} QA pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb987a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load GPT-Neo model\n",
    "MODEL_PATH = \"./models/gptneo_model\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_PATH, torch_dtype=dtype).to(device)\n",
    "\n",
    "def extract_number(text):\n",
    "    match = re.search(r\"[-+]?[0-9]*\\.?[0-9]+%?\", text)\n",
    "    return match.group(0) if match else text.strip()\n",
    "\n",
    "def gptneo_infer(question):\n",
    "    prompt = (\n",
    "        \"You are a financial analyst.\n",
    "\"\n",
    "        f\"Question: {question}\n",
    "\"\n",
    "        \"Provide only the final numeric answer in percentage format.\n",
    "\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=10,\n",
    "            do_sample=False\n",
    "        )\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return extract_number(decoded.split(\"Answer:\")[-1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5847608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on first 100\n",
    "results = []\n",
    "for q, gt in qa_pairs[:100]:\n",
    "    pred = gptneo_infer(q)\n",
    "    results.append({\n",
    "        \"question\": q,\n",
    "        \"ground_truth\": gt,\n",
    "        \"gptneo\": pred\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_close(pred, gold, tol=0.01):\n",
    "    try:\n",
    "        p = float(pred.replace('%', '').replace('$', '').strip())\n",
    "        g = float(gold.replace('%', '').replace('$', '').strip())\n",
    "        return math.isclose(p, g, rel_tol=tol)\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def mape(pred, gold):\n",
    "    try:\n",
    "        p = float(pred.replace('%', '').replace('$', '').strip())\n",
    "        g = float(gold.replace('%', '').replace('$', '').strip())\n",
    "        return abs((p - g) / g) * 100 if g != 0 else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def smape(pred, gold):\n",
    "    try:\n",
    "        p = float(pred.replace('%', '').replace('$', '').strip())\n",
    "        g = float(gold.replace('%', '').replace('$', '').strip())\n",
    "        return 100 * abs(p - g) / ((abs(p) + abs(g)) / 2) if (p + g) != 0 else None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc24ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"exact_match\"] = df[\"gptneo\"].str.strip().str.lower() == df[\"ground_truth\"].str.strip().str.lower()\n",
    "df[\"numeric_close\"] = df.apply(lambda row: numeric_close(row[\"gptneo\"], row[\"ground_truth\"]), axis=1)\n",
    "df[\"mape\"] = df.apply(lambda row: mape(row[\"gptneo\"], row[\"ground_truth\"]), axis=1)\n",
    "df[\"smape\"] = df.apply(lambda row: smape(row[\"gptneo\"], row[\"ground_truth\"]), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {\n",
    "    \"Exact Match Accuracy\": df[\"exact_match\"].mean(),\n",
    "    \"Numeric Match Accuracy\": df[\"numeric_close\"].mean(),\n",
    "    \"Mean MAPE\": df[\"mape\"].mean(),\n",
    "    \"Mean sMAPE\": df[\"smape\"].mean()\n",
    "}\n",
    "pd.DataFrame([summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e5d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print failed numeric matches\n",
    "for i, row in df.iterrows():\n",
    "    if not row['numeric_close']:\n",
    "        print(f\"Q: {row['question']}\")\n",
    "        print(f\"Expected: {row['ground_truth']} | Predicted: {row['gptneo']}\")\n",
    "        print(\"-\" * 50)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}